{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1. Text-Based Short Video Generation Using AI"
      ],
      "metadata": {
        "id": "b8zqhZSLLhv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q diffusers transformers accelerate torch torchvision safetensors imageio imageio-ffmpeg\n",
        "\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "from IPython.display import Video, display\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "model_id = \"damo-vilab/text-to-video-ms-1.7b\"\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\"\n",
        ").to(\"cuda\")  # GPU only\n",
        "\n",
        "prompt = \"A serene landscape with a flowing river and birds flying overhead.\"\n",
        "\n",
        "result = pipe(prompt, num_frames=16)\n",
        "frames = result.frames[0]\n",
        "\n",
        "video_path = \"/content/generated_video.mp4\"\n",
        "imageio.mimsave(video_path, [np.array(f) for f in frames], fps=8)\n",
        "\n",
        "print(\"Video generated and saved at:\", video_path)\n",
        "display(Video(video_path, embed=True, width=560))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rglNOUBdLjOQ",
        "outputId": "644f22f9-6e02-4013-eda5-a843bfe59bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Image-Based Short Video Generation Using AI"
      ],
      "metadata": {
        "id": "DRel3JMDLqN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install required libraries\n",
        "!pip install -q diffusers transformers accelerate torch torchvision safetensors imageio imageio-ffmpeg\n",
        "\n",
        "# STEP 2: Import dependencies\n",
        "from diffusers import StableVideoDiffusionPipeline\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import imageio\n",
        "from google.colab import files  # for uploading files\n",
        "from IPython.display import Video, display\n",
        "\n",
        "# STEP 3: Upload your image\n",
        "print(\"Please upload an image file (jpg/png).\")\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]  # get uploaded file name\n",
        "\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "image = image.resize((512, 512))  # resize for model\n",
        "\n",
        "# STEP 4: Load the video diffusion model\n",
        "model_id = \"stabilityai/stable-video-diffusion-img2vid-xt\"\n",
        "pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\"\n",
        ").to(\"cuda\")  # use GPU\n",
        "\n",
        "# STEP 5: Generate a short video\n",
        "result = pipe(image, num_frames=6)  # 6 frames for low memory\n",
        "frames = result.frames[0]\n",
        "\n",
        "# STEP 6: Save and display video\n",
        "video_path = \"/content/generated_video.mp4\"\n",
        "imageio.mimsave(video_path, [np.array(f) for f in frames], fps=8)\n",
        "\n",
        "print(\"Video generated and saved at:\", video_path)\n",
        "display(Video(video_path, embed=True, width=560))\n"
      ],
      "metadata": {
        "id": "x4uXrbXLLsAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WW0KYDSEL6BG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}