{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##1. Generate a short creative story based on a given theme using a pre-trained GPT-2 model"
   ],
   "metadata": {
    "id": "DkhbtgaUJpcj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "prompt = \"A brave astronaut lands on Mars and discovers\"\n",
    "result = generator(prompt, max_length=60, num_return_sequences=1)\n",
    "\n",
    "print(\"Generated Story:\\n\")\n",
    "print(result[0]['generated_text'])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624,
     "referenced_widgets": [
      "98520f10c1ae48f1a2150a360bf2bb3a",
      "531f5dac8ca7433aaa7c51b967ac307f",
      "f5ac0419a3064950a8fe5cab73709608",
      "528836b9a5c3439382a4c819763b62fe",
      "65939d3844d84d49a78d6f6fb0faf53d",
      "bd32a9800c2c45cb95ab6d850cc0c2ee",
      "cf8c7b4f5b394c1b8bf0a25998d8d6da",
      "90ed889c7c464232af6d1eacfc8fffc7",
      "68b9f12769cf4b12b6aac731dab69f0b",
      "6a52157887354e269c60800f5630f595",
      "6de8885b2e4e4d74bc6e0f829dfbce37"
     ]
    },
    "id": "Uu80ayKYJsBy",
    "outputId": "f47cf271-aeb4-418d-8469-82b3860974a4"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98520f10c1ae48f1a2150a360bf2bb3a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generated Story:\n",
      "\n",
      "A brave astronaut lands on Mars and discovers: \"The world has no need of you. We need to breathe. We need to breathe deeply. We need to think deeply. We need to feel. We need to build worlds, to conquer the unknown.\" Earth should go on making things better and more\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##2. Generate an image based on a descriptive text prompt using a pre-trained Stable diffusion model"
   ],
   "metadata": {
    "id": "qfMSgXv2Jxa5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade transformers==4.44.2\n",
    "!pip install --upgrade diffusers==0.30.2\n",
    "!pip install accelerate safetensors torch --upgrade\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "prompt = \"A beautiful sunset over a calm lake with mountains in the background\"\n",
    "\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "image.show()\n",
    "image.save(\"sunset_image.png\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4ae8993504b148c69d576c4f7ba4858f",
      "9a0cb00cab4b477aa20f1607412e39a5",
      "dc5630d6fdc24daba8ba74be1fbf8243",
      "dbb2b5004aea4b63828df960ee49e126",
      "b0c1db8481b64e3284f48b5e7b2afcb6",
      "7284bedba23c49269ba225ffd5ef94b2",
      "ec49f33869f94fbc97fa2793e13b3b5d",
      "34a4e9830d8b477bbafc718865f32588",
      "3b8cfed9ba804beca11461c1592c9c34",
      "aac437ff91d4402bb21f80df00d5d284",
      "abea0fd8a9f34353a83659f0e75ba3b9",
      "44a8dd6f2f8b426c9aae867e28dabc1a",
      "b25eefd41cb8415199f010e389956709",
      "8fdddbc5f54945a084c3bc5dc7e80705",
      "a540e822e14a425088d3acdcfbde2b1c",
      "be66677dcb07470b88052665daa5401a",
      "77fb0fa311b840979217149ae7a541f7",
      "0c130c5d6d6247e99418d748effd6c7b",
      "8edd65010b234426ac7885edef68e230",
      "f5c8454ff08e4000938d1b984fcd1803",
      "a373bedcc4b84a53ae9db9a3a40b3ca7",
      "acd33d024f714c1382557652c830091d",
      "00d1e334b7a74dfa95d0526f88171ad8",
      "60f6e55ab8a34ef1a0b1ff2c65b7927a",
      "854e819cc6544fe5ba70b2c066498860",
      "73b962a5b41746a4b9d59a2d8fa14c91",
      "48d27ae15a004478b2a2d1173754491f",
      "692d43d6f4404650baa956ed5384903c",
      "9933752e6b6c40798ae39d801534f6ec",
      "45caf203d75a4c588564a2d3abe9bc4f",
      "7b6124c8dfa240cb877303739fec6dc0",
      "73d493051bd24326930219b9ce968c87",
      "5eb0a8ddd9064cbe850002ebb174dc68",
      "93023d344b4d42dbad781604edcd386c",
      "481e50669f554697ae204e56baa9def5",
      "69d732ea42c2484aa11420111e654358",
      "6c33ae7667c2498d9e4cae2ba1711458",
      "0cf90d40702a44b78b5fada5c9e9e971",
      "142f0566dc1148b28f019bd66049198c",
      "7b618752866c46319191c551bb77a1e3",
      "1597cef2614d4aa7810a2ef360c10cf1",
      "7b467d2aa2544f7680ccb9b5604667ee",
      "0ca0aded70e0464eacda839782eca351",
      "433d1302bb8b428aa1809de468c58f76",
      "4e9c32f567ec492fbcf6928777fb0537",
      "90b2d6e209dc48d19df9d512aba6d041",
      "fdd08cb9426949eaaf29ec917dd74175",
      "7557315e583947be831e72b42b78624d",
      "e9c04294855f46b68ffb260700dc0c8b",
      "7c64c871cb3c4968ab54046e8cc02a53",
      "68233569fc7f4a159e68880d4205417f",
      "becf6b3b76b44a28bf6dedddda110a6b",
      "ca474a3e772e4006b67e0cc0e33fff44",
      "db0bd11425ec49a68f395aa18dfb818b",
      "aacbb7ec336b4ded9e5b26b1cb8e46de",
      "1df979b753cc4de2a41ebc9f150a5867",
      "85f0d57ee4c447a88d373aac1515c715",
      "86b3286e7952458cbeb550bd393dd1b7",
      "1e79698f28d34cffb8facf02894fedc1",
      "f33c256c819c4490823274e3bfe8405f",
      "ebdc95c1db444d889d4cc5b08a1e0868",
      "554446c95b454c8a947e731e3533db9d",
      "9d53ab450b5e46528fcbf2f795834f5b",
      "5163e5150b784ce68a4e06a591f413c7",
      "3b05e2289bdc4d49a032fe765cf70b97",
      "213a344f95834e199e8de309022ce42e",
      "4d12c0f4b4454184a3f1fa518a701008",
      "c812ff3d56484978b7ce9b573bb0b562",
      "949cfb6c6e8446f6957262cd4278a574",
      "89c768d0cb3e44559da62134fc32a6c0",
      "3c24b10018cd44c897be861ea87f7f1d",
      "c8c8344d8c46492b9648264e6412c683",
      "9ceee8a9189e4d0b92dcd1633216dc17",
      "20fb03faf81a4b17abce2c3bd7cc24ef",
      "16a2c9aea118477da84ef6e6b40f99a8",
      "27591e6dad254f728e3b5c511e35c177",
      "903f63551f014286bae0ad9343ce0963",
      "e523bbddc5ca46c49f92ac0ebd802c91",
      "791c369797de49b9916d1666e17fbf02",
      "226b908d46e044e09f3587b604969a8a",
      "b33551be8dd24bd582344b66ce08a2b5",
      "4d4c5508b48f49fbac7a1867bba3be9c",
      "8aa966597c07443fbdefc7b0ff8690c9",
      "450fafee35ec491fb22aa6d2182136f6",
      "945b9753426643bd9aaa1a895b31d670",
      "a15df5e2c52a4d118192c9b6c6aadaaa",
      "35b9f6b478b84c67bf9ed93fe5bde446",
      "e2d38e3a82bc4ac4b0beab90023390bb",
      "5c821d5a030b414581091cd4b298e2d4",
      "7bd02efd77c2487e83ba0619adf78fb8",
      "889304dd4ec845d180fe6c0a5ec3c5b3",
      "f8feadd499ed4812915c81f0989fc633",
      "41ade32a2a4d441ea65814f50e0e1a4e",
      "36aa7d826397414d8942ce2c1347dd64",
      "c34622a265674497a84cc47616f0bdc8",
      "c50d6a1e9fba446d9b4abb2837f885c4",
      "c37459a236464dad946b89b8e3b7ebc9",
      "da87425b7f184012948222194f2b9ad3",
      "b85bfd60a4644910bf5afa6a13a5c90a",
      "ac06bee511c04ac1a1825e26b129e5ec",
      "ded2aaa0480d4d99af2d3c72d5ae2c5d",
      "2c80a664e2c940bdbba8939f99e7d3c9",
      "58f27217921a4001b731205b59742d17",
      "ade5c727a7ab478d81ed6de768fba175",
      "79d629ba3ffe449bb948cf281796e65f",
      "f141d510d9504e9b810ae431f97187b4",
      "95a0b91cf7fb4c13a652e4cef6095065",
      "3aa81afec1bf49e78900b84fa0a116e4",
      "712ee0e56be141d087d212a330bbcd06",
      "93131fdae146469cb661eecb147b28d8",
      "98610931cb584fd3b2c30eb9ecf3d974",
      "7e7cefc6c1a64e18a13b4168095b35b3",
      "2a26d8442fe64e99961151c0adce8e16",
      "9dab620f8b3f4c4ba20f4edff8f8680c",
      "741a51f42c09479ab5534b4d6d137b41",
      "d8bd9b0b6bd34c1e88b2b2eff747102c",
      "5a077802f5804e038bc68e46c69c03cf",
      "fd6c86f77afd4d8fbb0a50a7df921a17",
      "d2a3e7d10a584f7eb2d182e4a10a2c25",
      "f230651966524a2588ed76fd8460313e",
      "d9d1717bf7a949d2972ff9cd70cb3fe6",
      "7a311afa281346a2adf160f945138294",
      "e89a2569cb374b0ab458c21295e080a2",
      "ef882009282b47b5bc5242ca2770a2b3",
      "96f85bc28a804ecc9511135a4cdd75ec",
      "8069bd844554444aa0727a6f553b5af9",
      "c08c1316d9254fbd9c73c055c7b4bbe5",
      "48dd37aa122e4fd88e89ec929ad286a1",
      "2c996fc159ba439ba5a774a29a15fece",
      "e4ebb8410eb04647b809885e62bb167d",
      "d823b64afeea4f99ae36a91f34e47366",
      "06549e72b6ed4eeeaac9aab18c6998c0",
      "5b43329490dc4181b3f826eeca084ffe",
      "5210e0110eb64d36bdd49c95fd9247ba",
      "5d55404610384cf388c5ba9dd5980135",
      "bacfe44f2e0b412ab03bcc5b5630923f",
      "b267d16777c245f98b45e5ae8c718b54",
      "b7d03227abb94056b7005dd2ae7ec61f",
      "148fbfb6d1ec4fae9f5c3fb75cae8499",
      "0dc3d23be0994bdbbc97e4881c171e92",
      "911030753e5c44a7937dbd11be65a25c",
      "2f7ca271907c4e08aa37028962fa5be6",
      "c12cbb3d109e4002bb9008c5fa6aa74a",
      "c1351cb571a74e1b9ebe70b39a1d1b46",
      "501d5d64f1424661ba3fbcbdc13a1bed",
      "967ebcac2d5a4c049c486343d6517eff",
      "8bf4e20dca3749deaa30d381a5cdfeb1",
      "d95fa4afa68641b5a459dfa73ec5daf3",
      "5a8da8ae8f9446b0ac3d5504467e2480",
      "dcd57265834d44ec9c6865a9d45fe193",
      "c0e52cfb2a2f4f1ca051ff5f1367e3dd",
      "3b843b3d2d61486d974087af3837c635",
      "efa3774efd304ba280a27c8d537491dd",
      "4af79c2d00134599adc8d8b20ce8663c",
      "910a41b03fbc438c921615baffaa9c35",
      "41b07900103f4bb19ec5fc7ccb977d3d",
      "736e7aeb082b4c939e6030463ea1c84a",
      "921388046b0f401b86bdceff9abd489d",
      "74dac995eb49416da7de4979c61596c4",
      "760cb295d6174fe0bd86c30ce3e55757",
      "5a96b320d36c4d87ad75b1cb21cad6ee",
      "79613b229eb94a2da51aabbf5004d53d",
      "32a95cd0ead54b6caf17f8576d01393d",
      "873c6454b48f4d9388063368acced5e2",
      "93767d5889b44e15898507aced536a75",
      "99bb67d9f5ae4aa4bc9321a6ead50f5f",
      "b0a59d8c6d794c5ea141e3c0d8296d87",
      "599cb8ac2224444cab1f6343108fc9df",
      "3f86e90a760c409f9f957122a4f95579",
      "b4306436d32c41c78f0e4c4fb3674c79",
      "7ffec9f5a30344459ede6edbd9a7aec4",
      "f3ca435eb850430f89f9017a497fc324",
      "16094163fb8f41b89ae057b02640f947",
      "90916c448f2b436ca2e01cb43201fb91",
      "17dd505fae1b43f58bcb755b11d91ee2",
      "e9c165ce69a9485f995cd8d0461f600d"
     ]
    },
    "id": "A06iCLxqJ3Qj",
    "outputId": "4f972c89-e540-4f08-c573-136dbbdb424b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers==4.44.2 in /usr/local/lib/python3.12/dist-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.11.12)\n",
      "Requirement already satisfied: diffusers==0.30.2 in /usr/local/lib/python3.12/dist-packages (0.30.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.30.2) (8.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.30.2) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.30.2) (0.36.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers==0.30.2) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.30.2) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.30.2) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.30.2) (0.4.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.30.2) (11.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.2) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.2) (6.0.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.2) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.2) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.2) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.30.2) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.30.2) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.30.2) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.30.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.30.2) (2025.11.12)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (0.33.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.4.4)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m778.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, accelerate\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.5.0\n",
      "    Uninstalling triton-3.5.0:\n",
      "      Successfully uninstalled triton-3.5.0\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.4.4\n",
      "    Uninstalling safetensors-0.4.4:\n",
      "      Successfully uninstalled safetensors-0.4.4\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufile-cu12\n",
      "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
      "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
      "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.9.0+cu126\n",
      "    Uninstalling torch-2.9.0+cu126:\n",
      "      Successfully uninstalled torch-2.9.0+cu126\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.33.0\n",
      "    Uninstalling accelerate-0.33.0:\n",
      "      Successfully uninstalled accelerate-0.33.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
      "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.12.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 safetensors-0.7.0 torch-2.9.1 triton-3.5.1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "accelerate",
         "nvidia",
         "safetensors",
         "torch",
         "torchgen",
         "triton"
        ]
       },
       "id": "6d0c95462159434790e619c2d5983448"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ae8993504b148c69d576c4f7ba4858f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44a8dd6f2f8b426c9aae867e28dabc1a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00d1e334b7a74dfa95d0526f88171ad8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93023d344b4d42dbad781604edcd386c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e9c32f567ec492fbcf6928777fb0537"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1df979b753cc4de2a41ebc9f150a5867"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d12c0f4b4454184a3f1fa518a701008"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "safety_checker/model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e523bbddc5ca46c49f92ac0ebd802c91"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c821d5a030b414581091cd4b298e2d4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "text_encoder/model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac06bee511c04ac1a1825e26b129e5ec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98610931cb584fd3b2c30eb9ecf3d974"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a311afa281346a2adf160f945138294"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b43329490dc4181b3f826eeca084ffe"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1351cb571a74e1b9ebe70b39a1d1b46"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "unet/diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "910a41b03fbc438c921615baffaa9c35"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vae/diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99bb67d9f5ae4aa4bc9321a6ead50f5f"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##3. Generate Creativity with AI: Stories and Visuals from a Single Prompt"
   ],
   "metadata": {
    "id": "MBT-Wq2KJ8rh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install --upgrade transformers==4.44.2\n",
    "#!pip install --upgrade diffusers==0.30.2\n",
    "#!pip install accelerate safetensors torch --upgrade\n",
    "from transformers import pipeline\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from IPython.display import display\n",
    "import torch\n",
    "\n",
    "# Prompt\n",
    "prompt = \"A futuristic city with flying cars and glowing skyscrapers\"\n",
    "\n",
    "# Text generation\n",
    "story_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "story_result = story_generator(\n",
    "    f\"Write a short story about: {prompt}\",\n",
    "    max_length=120,\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=3\n",
    ")\n",
    "story = story_result[0]['generated_text']\n",
    "\n",
    "print(\"Generated Story:\\n\")\n",
    "print(story)\n",
    "\n",
    "# Stable Diffusion \u2014 GPU only (no fallback)\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "# Display and save\n",
    "display(image)\n",
    "image.save(\"generated_future_city.png\")\n",
    "\n",
    "print(\"\\nImage saved as 'generated_future_city.png'\")\n"
   ],
   "metadata": {
    "id": "be9satnmKXUu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##4. Generate a Story from an Image Using AI"
   ],
   "metadata": {
    "id": "OB8I8hRnK28i"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers torch pillow\n",
    "\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, pipeline\n",
    "from PIL import Image\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload an image (jpg/png):\")\n",
    "uploaded = files.upload()\n",
    "image_path = list(uploaded.keys())[0]\n",
    "image = Image.open(image_path)\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "caption_ids = model.generate(**inputs)\n",
    "caption = processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "print(\"\\nImage Caption:\", caption)\n",
    "\n",
    "story_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "story_prompt = f\"Write a short story about this: {caption}\"\n",
    "story = story_generator(story_prompt, max_length=80, num_return_sequences=1)[0]['generated_text']\n",
    "print(\"\\nGenerated Story:\\n\", story)\n"
   ],
   "metadata": {
    "id": "kkD3CvEhK7xz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##5. Generate a descriptive caption for a given image to explain what is happening in it."
   ],
   "metadata": {
    "id": "8paT0QbjLFZX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers torch pillow\n",
    "\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload an image (jpg/png):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "image_path = list(uploaded.keys())[0]\n",
    "image = Image.open(image_path)\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "caption_ids = model.generate(**inputs)\n",
    "caption = processor.decode(caption_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\nImage Caption:\")\n",
    "print(caption)\n"
   ],
   "metadata": {
    "id": "G7ENpxwALNI8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "nVYjTY1sLUYy"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}