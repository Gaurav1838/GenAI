{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4A-pvihGvRs"
   },
   "source": [
    "##1. Install the transformers library and generate text using GPT-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868,
     "referenced_widgets": [
      "8a7e569348c941058d3ab63848ee9816",
      "0cde17bb3995441c989f175f2f48fd16",
      "4398e4dbc24b4f9da1a0e7980d5ba2f5",
      "60ac4073a7184654a1399299bb2155ca",
      "6a6b8265b3d24735bac208eebc54ebf3",
      "0948bb84be1c427cb3b949a1ea4cd70d",
      "629f726fdecb4a6c847717e64516214d",
      "e468ac59935149509d4f9ab10b41974d",
      "f179c8082dca4568a6ec0f2629c6caab",
      "e66869e645664d02940d7a2f3f81cd2c",
      "29fed1bd0b7d40508eb74ba4021f707c",
      "e215aa72bed04f36969f4545cdc62324",
      "6a115aeff79b45f791a771bd31081de3",
      "7c8f822e22884c05b7a8b870130c598b",
      "b6088d555a8243ac9d1c538c85703083",
      "8a6196befc63469cab2174b00ff92be6",
      "9a5426b9e7e944f5bce9937bd9536aa4",
      "18af2fd1213742e1a831b192460999ba",
      "5afb69fa52844587abe36c634b2daaed",
      "83ca2ad450874eef8248205dc250a6e0",
      "44bd6aafbf4543409a9c92d7346b53fe",
      "66fff6caa2a84bb88fc2dd38874fa967",
      "5b529976dc1d45d291e976d3004fdfc7",
      "214a27a433c247f9844ec92b2c054ada",
      "a8780c4dd70b470dac37f7c4ee7f9794",
      "ed240546becc4392bfb7b920f8a7e2b3",
      "8786c5be8fa945ab97bbdf01b5c5fdcc",
      "e0e2539977444d1986250438f77a45f7",
      "95edbeadcfcc4a459377aa644e2adfe6",
      "cef4aaeabf85429c8b40adceb5467da2",
      "2aea4d637f9c45b4916dd2b94ddf5806",
      "41dcb0aba7a2496ea55595ae5e195278",
      "c9f4d9a9b6ee46e28ade3bd8cea43d46",
      "b0ed654fad8543dbafde3aebcd9eb10f",
      "9dc66a2d787f4c9182fd096645af39fe",
      "70a899416c014cac99bfe27f839f221a",
      "ac5b5d5dac814f2188afa81b514cc5d2",
      "5f49a63d409c49f6b862f91aa2261240",
      "1fbdf7445a8042d3a442f6aa84641ceb",
      "4c429c90f2d340fc9a18bd0729f32284",
      "73deda98efb846718b01fe00af4cef45",
      "8e787a131a7346c8a8cfac16fd0dd259",
      "fba244c1d2ca440980e73a713c46b330",
      "c9ec6737e26146adb850e7c53a886a9f",
      "da8f6b0576f542eb9895e9c013d0fe7f",
      "1a5200809ace4145bf67ae742d7af9d9",
      "8d3d6ae53491434db227a343a4dc2af6",
      "d5a35df7e4fd4ba7bc3ddedad3c2bb8f",
      "f1cb21538847495ebc7425655dde503d",
      "728e0157d1d84961b1a9032d7457fe11",
      "c103725532ea49759ddb8da3ff1f582f",
      "e2276a79d5e242abbfa2ffbace9d5e13",
      "01a65ec2b2674ba2841d60a9b06eac83",
      "1b91e85f751a4fc282bf45208edb1a47",
      "27bc4c57d4ec4ce0b051205cb1bca931",
      "51e9e03a794541df836252e1cdbd36a1",
      "2a54bfa36b8742b28761a63ff5387487",
      "0fcd7057097d46a2bc6058c06648ea3d",
      "643e0a22076a444f8309571303a2b982",
      "09cffbe9f18e4343b43ce4d6b5a62e4e",
      "767eee1f86b749f7a9009e1d863d85fa",
      "f0fd40b588e04dc5846121348804e223",
      "c23ab8b6bffa4374965a1c0d0cc9622c",
      "3ebd63009eb64b8a9960b8a6a9309dac",
      "760bffbecd2043e7807f8c453cf03084",
      "61cc3c1b064f40cfa993ad394278b8d3",
      "aabc7fbcedf1468eb08eb268ac9064ea",
      "ece797f01f404901b5eb9c04cb1e99b7",
      "951a32cd5cce454faec6ab08b0f520e0",
      "1c554ebbfe5a4d3ea69ae6b4290efda3",
      "38dcc8f0ae034ad7b552ee661c8205a0",
      "ca7ffecb31ef47c990a7ac5dab33168f",
      "61334cf905f349729e6678b323705e2a",
      "70169ee2d12e4ce1aa4837231adc8f71",
      "c32ad1e1b35a4249bbef8241f8875a4b",
      "f2cb33bfeb0c4858818d569bdbadd157",
      "d0d08f3aa9bf498bb02fa23c9c5924e0"
     ]
    },
    "id": "BqPoWDd3GcRw",
    "outputId": "67da3353-f617-429e-8c3e-7b058ee277eb",
    "state": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7e569348c941058d3ab63848ee9816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e215aa72bed04f36969f4545cdc62324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b529976dc1d45d291e976d3004fdfc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ed654fad8543dbafde3aebcd9eb10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8f6b0576f542eb9895e9c013d0fe7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e9e03a794541df836252e1cdbd36a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabc7fbcedf1468eb08eb268ac9064ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in the world of Artificial Intelligence, there was a time when an AI could not think. Or at least, not think. In the very long run, artificial intelligence has been a good thing for human beings, and we've been able to avoid it through various means. The problem of human mental and emotional limitations is still present, but there are no limitations to the abilities of intelligent machines. The problem of human physical limitations is still present, but the basic capabilities of an AI are no longer confined to the human body.\n",
      "\n",
      "The point is that a computer that can't fully understand how to do whatever it wants to do would never be a human, and it would be simply a human doing a job that we would not want a computer to do. The problem is one of using the human brain as a tool of the human mind, and it's often difficult to do.\n",
      "\n",
      "When we consider that a computer can't think in the way a human could, and can't think in the way a human would, it is hard to appreciate the implications of what humans are capable of. This is not a question of how a computer perceives the world, but how it perceives the world. But it's certainly not something that a human would be able to do.\n",
      "\n",
      "A computer can do something\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "prompt = \"Once upon a time in the world of Artificial Intelligence,\"\n",
    "results = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "\n",
    "print(results[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZC1ctFAIHDKl"
   },
   "source": [
    "##2. Text Generation using GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6i1M2NjG3YW",
    "outputId": "cff21195-53c3-494b-b542-9ff66b9ca1ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is transforming the world.\n",
      "The next step will be to develop a new kind of AI that can do things like predict what people are going through, and then use those predictions in real-time for other purposes such as predicting how they'll react when faced with an unexpected situation or even just reacting quickly enough so it doesn't take too long before someone else does something similar (like you\n"
     ]
    }
   ],
   "source": [
    "# Install and import\n",
    "!pip install transformers torch\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "input_text = \"Artificial Intelligence is transforming the world\"\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    max_length=80,\n",
    "    num_return_sequences=1,\n",
    "    temperature=0.9,\n",
    "    repetition_penalty=1.2,\n",
    "    no_repeat_ngram_size=3\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLZ5F_HvHP5k"
   },
   "source": [
    "##3. Sentiment Analysis using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 946,
     "referenced_widgets": [
      "abc143275804459b8aac82ed4c1eadfd",
      "e66571c5949b44508063c95dcf5b39b0",
      "f99cf206671c4b9082691b65990a896c",
      "0dbaa0c4bf3a4400877a679ebc6e77b6",
      "bdd0c9113b62436297f360f6f627eceb",
      "0b3dd3a19e07471893bda425988912d8",
      "9812dcd5a9384e5fb4882b6fa229bfc1",
      "73b15a39380543e088e030d4a48d7812",
      "1f5576f0b338412b9ab836f49a194926",
      "d1a39a6ac3904180a01d13c3fc785304",
      "cbdd5b67c5654e97bf6fb4bce25a7157",
      "5c9f60e1338f43378812cf304538db42",
      "070305222bd1477f906424b6ce2df6a6",
      "9a13d3b6a91741cd8113ae1de40e71c3",
      "750641204214461f938addaa7108a8dc",
      "ae10408963044da8be05c9c504422eb3",
      "21a1efb9b993485dbc4799202462b151",
      "fc21f78c9b904555ac160bd7e37cd708",
      "c356cb8431fa4f068bb127d48901615c",
      "30e1036096c54a4c85da5c6d3c5c3d6c",
      "9acc90b5cedf43028cd874046496a0d4",
      "26cea8bc2ba44981bd252772a38e0e75",
      "357395fbae094b07b9c4fc1cfc29e01c",
      "d77e222b71df45c9afa4badd0d9f9074",
      "3d9a81eb058443b5ad8aaaa0230028cb",
      "b7067cee386d42a29908fccb7f5fe342",
      "5436e88a8aab4d6cb5d8573867251c73",
      "6f439752a5594683819d70f6ea9a95a0",
      "ddacdd662d1a4ef98a9dbb9930a8e65f",
      "a6f71875a6984d6e803d86a63f1ae4be",
      "f81f4b6649a1480bb56db73c560d91fb",
      "19f486e2ab9d46b0a9100d937ad17d1c",
      "ae1783abf99f453c9b51ed51989e3550",
      "d1574158046a484eb5729fe98445258c",
      "d01e203459224427ab06ea072a334efc",
      "f9cbeac0519740b28db3146ae76b5a25",
      "348f244354c74d25a8d6eabb2d1d752e",
      "5655caf1e7e34fe4955b358cba2d2c05",
      "cb102cc8567c4f1992eab6900fd2495c",
      "0ebb59aa218242c3a305eb6c7a509960",
      "f4e4f80395844ba2b26cf8ff1dcacc42",
      "514d62bf84854ff29a89fe863c8669f8",
      "4145a89b61a34a0ab58aef17ca0b22e7",
      "fcbd7e4356ed4ccfab272b424816ad5f"
     ]
    },
    "id": "fbH2kaoJHSeZ",
    "outputId": "5c6da0fa-d36d-4965-90f3-282e4bee4e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc143275804459b8aac82ed4c1eadfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9f60e1338f43378812cf304538db42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357395fbae094b07b9c4fc1cfc29e01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1574158046a484eb5729fe98445258c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9996127486228943}]\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "result = classifier(\"I really love learning about transformers!\")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iel4A9tVHeeT"
   },
   "source": [
    "##4. Text Summarization using BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "referenced_widgets": [
      "f311ee61f2fc43918c884c6dd0741c5c",
      "2a66e03127654dfe9a08d35d6de4c111",
      "e271f754a7af47eaa50cc56948bc1b42",
      "cebaeeeeb1fc4ea090ca527b54516149",
      "69f97ac7a232492f801f8bfd4f2cfcaa",
      "52850410ea6946c3ab5894e83017b2be",
      "53776bddbe6345aea93bedc75bcf751b",
      "053a713033d24c7db703f31a0d7ede0a",
      "d60e2c786a4c49bc8a26c707e7667b31",
      "d522d05e587946099412412e96e76a72",
      "dd99afdadb134adeb568be4cfed58f74",
      "9aee5d197902454f9e78623c18efa282",
      "17c2535e21fc4e998ba63ff366259f2c",
      "fb563444527a4f5b80b856974137e822",
      "4e3cf03053ba4afa884d7986b8252d99",
      "43d8066273c240e9a7d6a0dcb6bdfb2d",
      "4fd8b3585ee4482c97c8254cc14269be",
      "7016b8b70a5248908aa79b512f71d254",
      "b9e119be23ff47c195ab1351ae717f01",
      "5af4271bf87243ccbeb76fb2747e19ce",
      "dacb2e79c67b4d3984a5982bd0813202",
      "8587a9c0539544219688fd35f750a501",
      "525fdf01832946acb336bc9ff3ac3dd3",
      "91db2c0fe72c489dbecc340afb2406c3",
      "5a016671fd4548a9bb98c890ae8381b6",
      "f49624d5876247e0a1e597980110ebb2",
      "4b3b3b83ebdd4146a4b5307e56e85d15",
      "c8b2efb7661e4c539cae6297a029098d",
      "de24040222cd4aba8b272ca682daef63",
      "1504e0fff7884b07b96d301f50796cd5",
      "e419ccd67235450198d9b96f7b1999bc",
      "2ba62d4dc0be4f06aba239351fd97b2c",
      "d284cef2ed5744c2a857269b6f2af9d0",
      "6946f2e8551d4065a01cf8c91ac1385a",
      "fa6b8198446f47918dd1f3414724d12d",
      "d11bed4d24b249fd8e41379fbddc1390",
      "9ce152329f8f4744a9f09278da613583",
      "9a36abe216d14c6e96bb98efb478825d",
      "d9c177070668455aa6434d596c78c0f1",
      "3440d4fab6614299b8c8179e5cc67ec3",
      "5f92298ebbc64e82b868e24b18bda3d6",
      "325d2c4e37524a23bfee4f7029c5cd31",
      "133a28e005c44100b8bbef3b6e82cfda",
      "60db06cf344a4b8a9aca956b6e95f960",
      "b75fd80d1a944ba8a87994386777361d",
      "1e733ebf812443a09bf4c3e63229e8ce",
      "6e5853908e664cd8a46573deb5925207",
      "85a97b1ae50a4932b5b1f7daf6963cc5",
      "c0f1836955234be2bc8a36065ca5689e",
      "81c9a936a71b4052adffba190ac4b12a",
      "8043275bb56e4ec49330e2e8b466646b",
      "1bab65bf56d94cb69ecead857baa1f30",
      "59de3be51e024feca01073f5e0432942",
      "01b157eec4284686b254053a284fd72e",
      "840212e747284dc8a4e689b67b7020b5",
      "7bb0119331534361a6f20b5888ad6cf7",
      "da8ec160e60a4014baa27a477ece97e1",
      "0edd2522a1414c6f92f52d202f9d77b5",
      "6cda9da42abd490ab08a94d5bb090a29",
      "520c162c41444588aeee5cfccdcc44a0",
      "e744a376c7a140a5b2b949dc62ed4192",
      "ee039e008f8649eeb05d4ef5f66a13d1",
      "d5c688316c0d4892ac5a4978fb7cb287",
      "f244050521e14df1bd374ac0e3975d5e",
      "7cbd0da58ba64c418ade30b966aac139",
      "5d48a382422641819ce4ad04905c0765"
     ]
    },
    "id": "bGwBhjICHlKS",
    "outputId": "f313028c-4037-4725-f8d4-1c32fe998dae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f311ee61f2fc43918c884c6dd0741c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aee5d197902454f9e78623c18efa282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525fdf01832946acb336bc9ff3ac3dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6946f2e8551d4065a01cf8c91ac1385a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75fd80d1a944ba8a87994386777361d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb0119331534361a6f20b5888ad6cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a subset of artificial intelligence that focuses on the development of algorithms that can learn and make predictions from data. It enables systems to automatically improve their performance without being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "text = \"\"\"Machine learning is a subset of artificial intelligence that focuses on the\n",
    "development of algorithms that can learn and make predictions from data.\n",
    "It enables systems to automatically improve their performance without being\n",
    "explicitly programmed. Machine learning techniques are widely used in various\n",
    "applications such as email filtering, speech recognition, medical diagnosis,\n",
    "and self-driving cars. By analyzing large amounts of data, these algorithms\n",
    "can identify hidden patterns, make accurate predictions, and support\n",
    "decision-making processes across industries. As data continues to grow,\n",
    "machine learning plays an increasingly vital role in advancing automation\n",
    " and intelligent systems.\"\"\"\n",
    "\n",
    "summary = summarizer(text, max_length=40, min_length=10, do_sample=False)\n",
    "\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2yYQMoOHxYO"
   },
   "outputs": [],
   "source": [
    "## 5. Text Generation using GPT-2 with BRAD Framework\n",
    "# Install required libraries\n",
    "!pip install transformers torch -q\n",
    "\n",
    "# Imports\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load the model\n",
    "model_name = \"microsoft/phi-2\"  # smaller, instruction-following model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Prompt\n",
    "prompt = \"\"\"Background: You are preparing content about Artificial\n",
    "Intelligence and its real-world impact.\n",
    "Role: Act as a technology expert and educator.\n",
    "Action: Explain how AI is transforming different industries in simple terms.\n",
    "Details: Keep the tone informative and inspiring for college students.\n",
    "Response:\"\"\"\n",
    "\n",
    "# Tokenize and generate output\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=200,\n",
    "    temperature=0.8,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "# Decode and print\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}