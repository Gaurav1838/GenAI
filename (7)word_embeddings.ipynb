{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Find Similar Words Using Word Embeddings"
      ],
      "metadata": {
        "id": "DKdkxzguOrQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Task: Load pre-trained word embeddings and take any input word from the user.\n",
        "###Return top 5 similar words."
      ],
      "metadata": {
        "id": "LVcbHy9_Ou4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Gensim\n",
        "!pip install gensim -q\n",
        "\n",
        "# Imports\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.downloader import load\n",
        "\n",
        "# Load pre-trained word vectors\n",
        "model = load(\"glove-wiki-gigaword-50\")\n",
        "print(\"Model Loaded Successfully!\")\n",
        "\n",
        "# Function to find similar words\n",
        "def find_similar_words(word, topn=5):\n",
        "    try:\n",
        "        similar = model.most_similar(word, topn=topn)\n",
        "        return similar\n",
        "    except KeyError:\n",
        "        return f\"'{word}' not found in vocabulary.\"\n",
        "\n",
        "# Input word\n",
        "word = input(\"Enter a word: \")\n",
        "result = find_similar_words(word)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nTop similar words:\")\n",
        "if isinstance(result, str):\n",
        "    print(result)\n",
        "else:\n",
        "    for w, score in result:\n",
        "        print(f\"{w} --> similarity: {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7wJcnV7PHxe",
        "outputId": "6731ed57-5778-46ca-ec6b-6eca112175e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n",
            "Model Loaded Successfully!\n",
            "Enter a word: hello\n",
            "\n",
            "Top similar words:\n",
            "goodbye --> similarity: 0.8538\n",
            "hey --> similarity: 0.8074\n",
            "! --> similarity: 0.7951\n",
            "kiss --> similarity: 0.7892\n",
            "wow --> similarity: 0.7641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Task:\n",
        "###Build a small word embedding model using FastText and use it to find similar words for any given input word, even if the word was not present in the training dataset."
      ],
      "metadata": {
        "id": "WG-Z7tTwPIU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gensim\n",
        "!pip install gensim -q\n",
        "\n",
        "# Import FastText\n",
        "from gensim.models import FastText\n",
        "\n",
        "# Example sentences\n",
        "sentences = [\n",
        "    [\"i\", \"love\", \"machine\", \"learning\"],\n",
        "    [\"word\", \"embeddings\", \"are\", \"useful\"],\n",
        "    [\"fasttext\", \"handles\", \"unknown\", \"words\"]\n",
        "]\n",
        "\n",
        "# Train FastText model\n",
        "model = FastText(sentences, vector_size=50, min_count=1)\n",
        "\n",
        "# Find words similar to \"learning\"\n",
        "similar_words = model.wv.most_similar(\"learning\")\n",
        "print(similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNRZiFTdPNoy",
        "outputId": "0c87380b-2843-4c90-9547-cd2975387a61"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('embeddings', 0.23739147186279297), ('word', 0.15370918810367584), ('fasttext', 0.07506413757801056), ('handles', 0.010171581991016865), ('i', -0.004249247722327709), ('are', -0.0609765499830246), ('love', -0.16465850174427032), ('machine', -0.19357778131961823), ('words', -0.23307032883167267), ('useful', -0.2368934452533722)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Using the same GloVe word embedding model, create a program that answers word analogies like:\n",
        "###“Man is to Woman as King is to ___ ?”"
      ],
      "metadata": {
        "id": "KZfy2XawPd1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gensim if not already installed\n",
        "!pip install gensim -q\n",
        "\n",
        "# Imports\n",
        "from gensim.downloader import load\n",
        "\n",
        "# Load pretrained embeddings\n",
        "model = load(\"glove-wiki-gigaword-50\")\n",
        "print(\"Model Loaded Successfully!\")\n",
        "\n",
        "# Function to solve analogies: A is to B as C is to ?\n",
        "def solve_analogy(a, b, c):\n",
        "    try:\n",
        "        result = model.most_similar(positive=[b, c], negative=[a], topn=1)\n",
        "        return result[0]\n",
        "    except KeyError:\n",
        "        return \"One or more words not in vocabulary.\"\n",
        "\n",
        "# User input\n",
        "a = input(\"Enter word A (e.g., man): \")\n",
        "b = input(\"Enter word B (e.g., woman): \")\n",
        "c = input(\"Enter word C (e.g., king): \")\n",
        "\n",
        "# Solve analogy\n",
        "res = solve_analogy(a, b, c)\n",
        "print(\"\\nAnalogy Result:\")\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAGjfUaiPlda",
        "outputId": "5a779880-61de-4641-abee-5fd11ecc1877"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded Successfully!\n",
            "Enter word A (e.g., man): man\n",
            "Enter word B (e.g., woman): woman\n",
            "Enter word C (e.g., king): king\n",
            "\n",
            "Analogy Result:\n",
            "('queen', 0.8523604273796082)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Given 3–5 words, find the one that does NOT match the others using word embeddings."
      ],
      "metadata": {
        "id": "Q0-nUXD8PtxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gensim if not already installed\n",
        "!pip install gensim -q\n",
        "\n",
        "# Imports\n",
        "from gensim.downloader import load\n",
        "\n",
        "# Load pretrained embeddings\n",
        "model = load(\"glove-wiki-gigaword-50\")\n",
        "print(\"Model Loaded Successfully!\")\n",
        "\n",
        "# Function to find the odd one out\n",
        "def find_odd_one(words):\n",
        "    try:\n",
        "        return model.doesnt_match(words)\n",
        "    except KeyError:\n",
        "        return \"Some words not found.\"\n",
        "\n",
        "# Input words\n",
        "words = input(\"Enter comma-separated words: \").split(\",\")\n",
        "words = [w.strip() for w in words]\n",
        "\n",
        "# Find odd one\n",
        "result = find_odd_one(words)\n",
        "print(\"\\nOdd one out:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEF9NKWHPy8j",
        "outputId": "2eef752a-58e4-42c0-9b69-b9ad055b79a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded Successfully!\n",
            "Enter comma-separated words: hello,world\n",
            "\n",
            "Odd one out: hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Using GloVe embeddings, compute the similarity between two sentences."
      ],
      "metadata": {
        "id": "bz-8qXR3QB8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gensim if not already installed\n",
        "!pip install gensim -q\n",
        "\n",
        "# Imports\n",
        "from gensim.downloader import load\n",
        "import numpy as np\n",
        "\n",
        "# Load pretrained embeddings\n",
        "model = load(\"glove-wiki-gigaword-50\")\n",
        "print(\"Model Loaded Successfully!\")\n",
        "\n",
        "# Function to compute sentence vector\n",
        "def sentence_vector(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    word_vecs = [model[w] for w in words if w in model]\n",
        "\n",
        "    if not word_vecs:\n",
        "        return np.zeros(50)\n",
        "    return np.mean(word_vecs, axis=0)\n",
        "\n",
        "# Function to compute cosine similarity between two sentences\n",
        "def similarity(s1, s2):\n",
        "    v1, v2 = sentence_vector(s1), sentence_vector(s2)\n",
        "    sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "    return sim\n",
        "\n",
        "# Input sentences\n",
        "s1 = input(\"Sentence 1: \")\n",
        "s2 = input(\"Sentence 2: \")\n",
        "\n",
        "# Compute similarity\n",
        "print(\"\\nSentence Similarity:\", similarity(s1, s2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W330Tt1iQF05",
        "outputId": "4583af0c-5cf3-4368-d1b4-eabfbd031107"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded Successfully!\n",
            "Sentence 1: hello man\n",
            "Sentence 2: how are you\n",
            "\n",
            "Sentence Similarity: 0.63890004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word Similarity Using Different Library (spaCy)\n",
        "###1. Use spaCy instead of Gensim to compute similarity between two words."
      ],
      "metadata": {
        "id": "bLs7Roa7QP71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install SpaCy and download model\n",
        "!pip install -q spacy\n",
        "!python -m spacy download en_core_web_md\n",
        "\n",
        "# Import and load model\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Input words\n",
        "w1 = input(\"Enter first word: \")\n",
        "w2 = input(\"Enter second word: \")\n",
        "\n",
        "# Convert words to SpaCy tokens\n",
        "word1 = nlp(w1)\n",
        "word2 = nlp(w2)\n",
        "\n",
        "# Compute similarity\n",
        "print(\"\\nSimilarity Score:\", word1.similarity(word2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Lsfm-HiFQYlw",
        "outputId": "ed48832d-e447-4e69-ff36-16988d138810"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1908793196.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import and load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_md\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Input words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jLXFpPzTQjmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}